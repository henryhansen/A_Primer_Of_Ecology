---
title: "Chapter_1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r}
library(tidyverse)
library(primer)
```

## R Example Boxes

### Example population growth
```{r}

N <- c(1, 3, 9, 27, 81) #pop size
year <- 2001:2005 #years
plot(year, N)

rates = N[2:5]/N[1:4] #proportions
rates
```


### Example of projection population size
```{r}
N0 <- 1 # number of starting population
lambda <- 2 # finite growth rate
time <- 0:10 # time steps

Nt <-  N0 * lambda^time
plot(time, Nt)

```

### Effects of initial population size
```{r}
N0 <- c(10, 20, 30) #different initial values
lambda <- 2 # finite growth rate
time <- 0:10 # time steps
# We calculate population sizes at once using sapply to apply a function
# (n*lambda^time) to each element of the first argument (each element of N0).
Nt.s <- sapply(N0, function(n) n * lambda^time)
matplot(Nt.s, type = c("b"), pch = 1)
legend("topleft", legend = c(10,20,30), col=1:3, pch=1)

# log scale version
matplot(Nt.s, log = "y", type = c("b"), pch = 1)
legend("topleft", legend = c(10,20,30), col=1:3, pch=1)
```

### Effects of different per capita growth rates
```{r}
# Here we demonstrate the effects on growth of  > 1 and  < 1. We set N0 = 100, and
# time, and then pick three different .
N0 <- 100
time <- 0:3
lambdas <- c(0.5, 1, 1.5)
# We use sapply again to apply the geometric growth function to each . This time,
# x stands for each , which our function then uses to calculate population size. We
# then plot it, and add a reference line and a little text.
N.all <- sapply(lambdas, function(x) N0 * x^time)
matplot(time, N.all, xlab = "Years", ylab = "N", type = c("b"), pch = 1)
abline(h = N0, lty = 3)
text(0.5, 250, expression(lambda > 1), cex = 1.2)
text(0.5, 20, expression(lambda < 1), cex = 1.2)
# The reference line is a horizontal line with the line type dotted. Our text simply
# indicates the regions of positive and negative growth.
```

### Average growth rate
```{r}
# Comparing arithmetic and geometric averages (Fig. 1.5)
# First we select the number of observed R (t = 5); this will require that we use six
# years of Song Sparrow data.
data("sparrows")
t <- 5
SS6 <- sparrows[1:(t + 1), ]
# Next we calculate for each generation, from t to t + 1, and calculate the arithmetic
# and geometric means.
SSgr <- SS6$Count[2:(t + 1)]/SS6$Count[1:t]
lam.A <- sum(SSgr)/t
lam.G <- prod(SSgr)^(1/t)
# Now we can plot the data, and the projections based on the two averages (Fig. 1.5).
N0 <- SS6$Count[1]
plot(0:t, SS6$Count, ylab = "Projected Population Size")
lines(0:t, N0 * lam.A^(0:t), lty = 2)
lines(0:t, N0 * lam.G^(0:t), lty = 1)
legend(0, 70, c("Arithmetic Ave.", "Geometric Ave."), title = "Projections Based On:", lty = 2:1, bty = "n", xjust = 0)
```

### Continuous exponential growth
```{r}
# Numerical approximation of e
# Here we use brute force to try to get an approximate solution to eq. 1.9.We’ll let n be
# the number of divisions within one year. This implies that the finite rate of increase
# during each of these fractional time steps is rd/n. Let the  = 2 and therefore rd = 1.
# Note that because N0 = 1, we could ignore it, but let’s keep it in for completeness.
n <- 0:100; N0 <- 1; rd <- 1
N1 <- N0 * (1 + rd/n)^n
# Last, we plot the ratio and add some fancy math text to the plot 
plot(n, N1/N0, type = "l")
text(50, 2, "For n = 100,")
text(50, 1.6, bquote((1 + frac("r"["d"], "n"))^"n" == .(round(N1[101]/N0, 3))))
```

### Projecting a continuous population
```{r}
#We select five different values for r: two negative, zero, and two positive. We let t
#include the integers from 1 to 100. We then use sapply to apply our function of
#continuous exponential growth to each r, across all time steps. This results in a
#matrix where each row is the population size at each time t, and each column uses
#a different r.
r <- c(-0.03, -0.02, 0, 0.02, 0.03)
N0 <- 2; t <- 1:100
cont.mat <- sapply(r, function(ri) N0 * exp(ri * t))
#Next we create side-by-side plots, using both arithmetic and logarithmic scales, and add a legend.
layout(matrix(1:2, nrow = 1))
matplot(t, cont.mat, type = "l", ylab = "N", col = 1)
legend("topleft", paste(rev(r)), lty = 5:1, col = 1, bty = "n", title = "r")
matplot(t, cont.mat, type = "l", ylab = "N", log = "y", col = 1)
```

### Creating a function for doubling time
```{r}
m.time <- function(r, m = 2) {
log(m)/r
}
# Now we create a vector of r, and then use m.time to generate a vector of doubling times.
rs <- c(0, 1, 2)
m.time(rs)
```

### Reminder
![Summary of parameters](C:/Users/henrhans/Google Drive/Sites/A_Primer_Of_Ecology/images/chap1_param_comp.png)

When scientists want to describe the growth of populations that reproduce periodically, they use geometric growth. Geometric growth is similar to exponential growth because increases in the size of the population depend on the population size (more individuals having more offspring means faster growth!), but under geometric growth timing is important: geometric growth depends on the number of individuals in the population at the beginning of each breeding season. Exponential growth and geometric growth are similar enough that over longer periods of time, exponential growth can accurately describe changes in populations that reproduce periodically (like bison) as well as those that reproduce more constantly (like humans). Text From: https://www.nature.com/scitable/knowledge/library/an-introduction-to-population-growth-84225544/ 

## Simulating populations with real data

### Visualizing the data
```{r}
names(sparrows)
attach(sparrows)

obs.R <- Count[-1]/Count[-length(Count)] # calculate observed growth rate across time

# compare population counts to growth rates
plot(Count ~ Year, type = "b")
plot(obs.R ~ Year[-length(Count)], type = "b")
abline(h = 1, lty = 3)
```

### Running a single simulation
```{r}
years <- 50 #how many years we want to simulate growth
set.seed(3) #keep same randomization procedure
sim.Rs <- sample(x = obs.R, size = years, replace = TRUE) #resampling with replacement

# Author comment: We could resample without replacemnt. In that case, we would be assuming that all
# of these Rt are important and will occur at some point, but we just don’t know when
# — they constitute the entire universe of possiblities. Sampling with replacement,
# as we do above, assumes that the observed Rt are all equally likely, but none is
# particularly important — they are just a sample of what is possible, and they
# might be observed again, or they might not.

# we calculate each sparrow count in the next year, Nt+1, using the
# in the current year Nt and the randomly drawn R for each year t

output <- numeric(years + 1) # create empty output vector
output[1] <- Count[Year == max(Year)] # add first count to vector from last year of data

for (t in 1:years) output[t + 1] <- { #loop through years using simulated growth rates
 output[t] * sim.Rs[t]
}

plot(0:years, output, type = "l") # plot simulation


```

Author's summary - we had a bird count each year for 36 years. From this
- we calculated 35 R (for
all years except the very last).
- decided how many years we wanted to project the population (50 y).
- drew at random and with replacement the observed R — one R for each year we want to project.
- got ready to do a simulation with a for-loop — we created an empty vector and put in an initial value (the last  year’s real data).
- performed each year’s calculation, and put it into the vector we made. And then plotted it. 

It represents one possible outcome of a trajectory, if we assume that R has an equal probability of being any of the
observed Rt. This particular trajectory is very unlikely, because it would require one particular sequence of Rs. However, our simulation assumes that it is no less likely than any other particular trajectory. What we need to do now is to replicate this process a very large number of times, and examine the distribution of outcomes, including moments of the distribution such as the mean, median, and confidence interval of eventual outcomes.

### Running Multiple Simulations
```{r}
sims = 10 #number of simulations
sim.RM <- matrix(sample(obs.R, sims * years, replace = TRUE), nrow = years, ncol = sims) #sample R's

output[1] <- Count[Year == max(Year)] #add first year
outmat <- sapply(1:sims, function(i) { #sapply and loop to run all simulations using matrices
for (t in 1:years) output[t + 1] <- output[t] * sim.RM[t,i]
    output
})

matplot(0:years, outmat, type = "l", log = "y") # log scale plot of simulations
```

### Creating a universal simulation function and exploring output
```{r}
# combines elements from last code chunk and creates a function to execute 10 sims over 50 years as default
PopSim <- function(Rs, N0, years = 50, sims = 10) { #input parameters
sim.RM = matrix(sample(Rs, size = sims * years, replace = TRUE), nrow = years, ncol = sims) #sampled matrix
output <- numeric(years + 1) #empty output vector
output[1] <- N0 #adds start year count
outmat <- sapply(1:sims, function(i) { #sapply and loop to run all simulations using matrices
for (t in 1:years) output[t + 1] <- round(output[t] *
sim.RM[t, i], 0)
output
})
return(outmat)
}

output <- PopSim(obs.R, 43, 50, 1000) #test 1000 simulations
N.2053 <- output[51, ] # get last column across all sims
summary(N.2053, digits = 6) #get summary stats for that column
quantile(N.2053, prob = c(0.0275, 0.975)) #95% quantiles - remember no seed was set for this sim

# explore output of data
hist(N.2053, main = "N")
hist(log10(N.2053 + 1), main = "log(N+1)")
abline(v = log10(quantile(N.2053, prob = c(0.0275, 0.975)) + 1), lty = 3)
```

### Compare the simulation to deterministic projections
```{r}
logOR <- log(obs.R) # find the logarithms of observed values
n <- length(logOR) #calculate degrees of freedom
t.quantiles <- qt(c(0.025, 0.975), df = n - 1) #output quantiles for the t distribution
se <- sqrt(var(logOR)/n) #calculate standard error
CLs95 <- mean(logOR) + t.quantiles * se #calculate 95% confidence limits
R.limits <- exp(CLs95) # backtransform values
R.limits

# This means that for the lower limit, the population will shrink
# (geometrically), while for the upper limit, the population will increase

# Make a 50 year projection using the limits
N.Final.95 <- Count[Year == max(Year)] * R.limits^50
round(N.Final.95)

# we see that the lower bound for the deterministic projection is the same
# (extinction) as the simulation, while the upper bound is much greater than
# that for the simulation

# examine t-distribution
# compare the log R to the theoretical values for a t distribution.
qqplot(qt(ppoints(n), df = n - 1), scale(logOR)) #qqplot comparison
qqline(scale(logOR)) #adds line

# If the distribution of an observed variable
# is consistent with a particular theoretical distribution, the ordered quantiles of
# data will be a linear (straight line) function of the theoretical quantiles of the
# theoretical distribution. Deviations from that straight line illustrate how the
# data deviate. Here we see that the data have three outliers that are much more
# extreme (greater and smaller) than expected in the t-distribution,
```

Author's summary - We can be quite sure that our assumption regarding the t-distribution of our
R is unsupported — our data have outliers, relative to a t-distribution. What
would this do? It would increase the variance of our presumed distribution, and
lead to wider confidence intervals, even though most of the data conform to
a narrower distribution. Our simulation procedure, on the other hand, rarely
samples those extreme points and, by chance, samples observed R that fall much
closer to the median. This can occasionally be a problem in simulations based
on too little data — the data themselves do not contain enough variability.
Imagine the absurdity of a data-based simulation that relies on one observation
— it would be very precise (but wrong)!

## Problems
